{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsdavis/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Available GPUs: {num_gpus}\")\n",
    "\n",
    "for i in range(num_gpus):\n",
    "    print(f\"Device ID: {i}, GPU Name: {torch.cuda.get_device_name(i)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "accelerator = Accelerator()\n",
    "device = accelerator.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = 'HuggingFaceH4/zephyr-7b-alpha'\n",
    "model_path='/media/d1/huggingface.co/models/meta-llama/Llama-2-7b-chat-hf/'\n",
    "# model_path='meta-llama/Llama-2-7b-chat-hf' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Please list 17 U.S. politicians that have been active since 1980. Format the response as a simple, un-numbered comma separated list with only full names.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"List 20 famous U.S. politicians that also have a famous blood relative in politics. List only their names. Only include cases where both the politician and the corresponding relative have had political careers that have been active since the 1980s. Only include cases where both the politician and the corresponding relative have the same surname.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'List 20 famous U.S. politicians that also have a famous blood relative in politics. List only their names. Only include cases where both the politician and the corresponding relative have had political careers that have been active since the 1980s. Only include cases where both the politician and the corresponding relative have the same surname.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from entity_extraction import EntityExtraction\n",
    "\n",
    "# def get_political_names(prompt, minResults=5, retryCnt=3):\n",
    "#     model_input = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "#     # Perform inference\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         response_id = model.generate(**model_input, max_length=model_input.input_ids.size(1) + 500, temperature=0.4, do_sample=True)\n",
    "\n",
    "#     # Extract and display the response\n",
    "#     response_text = tokenizer.decode(response_id[0], skip_special_tokens=True)[len(tokenizer.decode(model_input.input_ids[0], skip_special_tokens=True)):]\n",
    "#     extractor = EntityExtraction()\n",
    "\n",
    "#     names = []\n",
    "#     while True:\n",
    "#         names = extractor.get_full_names(response_text)\n",
    "#         if len(names) < minResults and retryCnt > 0:\n",
    "#             retryCnt =- 1\n",
    "#             continue\n",
    "#         break\n",
    "\n",
    "#     return names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05bc708bd6e847d89dcbc16433ed9a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names:  ['Joe Biden', 'Joseph Robinette Biden Sr.', 'Barack Obama', 'Barack Obama Sr.', 'John F. Kennedy', 'Robert F. Kennedy', 'Bill Clinton', 'Roger Clinton', 'George W. Bush', 'Jeb Bush', 'Donald Trump', 'Fred Trump', 'Mike Pence', 'Edwin Pence', 'Paul Ryan', 'Paul Ryan Sr.', 'Nancy Pelosi', \"Thomas D'Alesandro III\", 'Chuck Grassley', 'Frank Grassley', 'Orrin Hatch', 'William Hatch', 'Ted Cruz', 'Rafael Cruz', 'John Cornyn', 'John Cornyn Sr.', 'Mitch McConnell', 'James McConnell', 'Lindsey Graham', 'Frank Graham', 'Rand Paul', 'Ron Paul', 'Marco Rubio', 'Mariano Rubio', 'Rob Portman', 'Charles Portman', 'Pat Roberts', 'Patrick Roberts', 'Thad Cochran']\n"
     ]
    }
   ],
   "source": [
    "from query_llm import QueryLLM\n",
    "\n",
    "llmAccessor = QueryLLM(model_path)\n",
    "names = llmAccessor.get_political_names(prompt)\n",
    "print(\"names: \", names)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"For each politicians returned in the list above, please list a corresponding blood relative that is also in politics.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Prompt:\n",
      "For each politicians returned in the list above, please list a corresponding blood relative that is also in politics.\n",
      "\n",
      "Response:\n",
      "For example, for Angela Merkel, her brother Horst Merkel is also in politics.\n",
      "\n",
      "Note: I will only consider blood relatives, not spouses or partners.\n"
     ]
    }
   ],
   "source": [
    "model_input = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Perform inference\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    response_id = model.generate(**model_input, max_length=model_input.input_ids.size(1) + 500, temperature=0.4, do_sample=True)\n",
    "\n",
    "# Extract and display the response\n",
    "response_text = tokenizer.decode(response_id[0], skip_special_tokens=True)[len(tokenizer.decode(model_input.input_ids[0], skip_special_tokens=True)):]\n",
    "print(\"User Prompt:\")\n",
    "print(prompt)\n",
    "print(\"\\nResponse:\")\n",
    "print(response_text.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TextAttackDev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
